{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Problem 1\n",
    "\n",
    "### Kyle Goyette ID: \n",
    "### Giancarlo Kerg ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_loc = '../Data/MNIST/mnist.pkl'\n",
    "data = np.load(data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Helper Functions\n",
    "\n",
    "Below are an assortment of functions used during the assignment. Each is described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# An MLP class with rigid 2 hidden layer, 800 hidden units architecture, using RELu's as the non-linearities\n",
    "# Parameters: l2_reg: if None, applies no l2 regularization, otherwise applies l2 weight decay\n",
    "#             dropout: the probability of droping a connection in the second hidden layer, if unentered no dropout is used\n",
    "#             loss_crit: \n",
    "class MLP_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self,l2_reg=None, dropout=None):\n",
    "        super(MLP_MNIST,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,800)\n",
    "        self.fc2 = nn.Linear(800,800)\n",
    "        if (dropout != None):\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.fc3 = nn.Linear(800,10)\n",
    "        self.insize = 28*28\n",
    "        self.l2_reg = l2_reg\n",
    "        \n",
    "        params = list(self.parameters())\n",
    "        for param in in params:\n",
    "            nn.init.xavier_uniform(param[0])\n",
    "            nn.init.constant(param[1],0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = nn.functional.relu(a1)\n",
    "        \n",
    "        a2 = self.fc2(h1)\n",
    "        if (self.dropout !=None):\n",
    "            d2 = self.dropout(a2)\n",
    "        else:\n",
    "            d2 = a2\n",
    "        h2 = nn.functional.relu(d2)\n",
    "        \n",
    "        logits = self.fc3(h2)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def prediction(self,logits):\n",
    "        \n",
    "        values, indices = torch.max(logits.data,1)\n",
    "        \n",
    "        return values, indices\n",
    "\n",
    "    def train(self, train_data,lr, batch_size, num_ecpochs, val_data = None, test_data = None ):\n",
    "        #prepare optimizer\n",
    "        batch_weight_decay = self.weight_decay/float(train_data.shape[0])\n",
    "        optimizer = tf.nn.optim.SGD(self.parameters(),lr=lr,weight_decay = batch_weight_decay )\n",
    "        train_loader, val_loader, test_loader = make_data_loaders(train_data,batch_size,val_loader,test_loader)\n",
    "\n",
    "        for epoch in num_epochs:\n",
    "            \n",
    "            for batch_index, (inputs,targets) in enumerate(train_loader):\n",
    "                inputs = torch.Variable(inputs,shape=[batch_size,self.insize])\n",
    "                targets = torch.Variable(targets, shape=[batch_size])\n",
    "                \n",
    "                logits = self.forward(inputs)\n",
    "                _,preds = self.prediction(logits)\n",
    "                correct += preds.eq(labels).sum()\n",
    "                \n",
    "                loss = loss_crit\n",
    "                \n",
    "                    \n",
    "                \n",
    "            \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
