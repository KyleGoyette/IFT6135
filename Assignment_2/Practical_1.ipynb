{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Problem 1\n",
    "\n",
    "### Kyle Goyette ID: 20085129\n",
    "### Giancarlo Kerg ID: 20109271\n",
    "### Alexandre Dos Santos ID: 20114844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Helper Functions\n",
    "\n",
    "Below are an assortment of functions used during the assignment. Each is described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# An MLP class with rigid 2 hidden layer, 800 hidden units architecture, using RELu's as the non-linearities\n",
    "# Parameters: l2_reg: if None, applies no l2 regularization, otherwise applies l2 weight decay\n",
    "#             dropout: the probability of droping a connection in the second hidden layer, if unentered no dropout is used\n",
    "#             loss_crit: \n",
    "class MLP_MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self,loss_crit):\n",
    "        super(MLP_MNIST,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,800)\n",
    "        self.fc2 = nn.Linear(800,800)\n",
    "        self.fc3 = nn.Linear(800,10)\n",
    "        \n",
    "        \n",
    "        self.insize = 28*28\n",
    "        \n",
    "        self.loss_crit = loss_crit\n",
    "        \n",
    "        params = list(self.parameters())\n",
    "        for param in params:\n",
    "            if len(param.shape)>1:\n",
    "                nn.init.xavier_normal(param)\n",
    "            else:\n",
    "                nn.init.constant(param,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = nn.functional.relu(a1)\n",
    "        \n",
    "        a2 = self.fc2(h1)\n",
    "        h2 = nn.functional.relu(a2)\n",
    "        \n",
    "        logits = self.fc3(h2)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def prediction(self,logits):\n",
    "        \n",
    "        values, indices = torch.max(logits.data,1)\n",
    "        \n",
    "        return values, indices\n",
    "    \n",
    "    def calc_l2_norm(self):\n",
    "        params = list(self.parameters())\n",
    "        l2_norm = long(0)\n",
    "        for param in params:\n",
    "            if len(param.shape)>1:\n",
    "                l2_norm +=  (torch.sum(torch.sum(torch.pow(param,2)))).data\n",
    "            else:\n",
    "                l2_norm += torch.sum(torch.pow(param,2)).data\n",
    "        return torch.sqrt(l2_norm)\n",
    "    \n",
    "    def evaluate_model(self,loader):\n",
    "        for batch_index,(inputs,targets) in enumerate(loader):\n",
    "            x, targets = Variable(inputs.view([-1,self.insize])), Variable(targets)\n",
    "\n",
    "            logits = self.forward(x)\n",
    "            _, preds = self.prediction(logits)\n",
    "            correct += preds.eq(targets.data).sum()\n",
    "            total += targets.size(0)\n",
    "        accuracy = (correct/float(total))\n",
    "        return accuracy\n",
    "        \n",
    "\n",
    "    def train_model(self, train_data,optimizer,batch_size, num_epochs,early_stopping=False, val_data = None, test_data = None, verbose=True ):\n",
    "        #prepare optimizer\n",
    "        train_loader, val_loader, test_loader = make_data_loaders(train_data,batch_size,val_data,test_data)\n",
    "        \n",
    "        bestValAcc = 0\n",
    "        bestNetwork = 0\n",
    "        train_accuracy = []\n",
    "        val_accuracy = []\n",
    "        test_accuracy = []\n",
    "        epoch_loss=[]\n",
    "        l2_norms=[] \n",
    "        for epoch in range(num_epochs):\n",
    "            losses = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "\n",
    "            for batch_index, (inputs,targets) in enumerate(train_loader):\n",
    "                inputs = Variable(inputs.view([-1,self.insize]))\n",
    "                targets = Variable(targets)\n",
    "                optimizer.zero_grad()\n",
    "                logits = self.forward(inputs)\n",
    "                _,preds = self.prediction(logits)\n",
    "                correct += preds.eq(targets.data).sum()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "                loss = self.loss_crit(logits,targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.data[0])\n",
    "\n",
    "                l2_norms.append(self.calc_l2_norm())\n",
    "            epoch_loss.append(np.mean(losses))\n",
    "            train_accuracy.append(correct/float(total))\n",
    "            \n",
    "            if (val_loader != None):\n",
    "                val_acc = self.evaluate_model(val_loader)\n",
    "                val_accuracy.append(val_acc)\n",
    "                            \n",
    "                if val_acc > bestValAcc:\n",
    "                    bestNetwork = self\n",
    "                    bestValAcc= val_acc\n",
    "                \n",
    "                if (early_stopping and val_acc < bestValAcc) :\n",
    "                    return bestNetwork\n",
    "        \n",
    "                \n",
    "            \n",
    "            if (test_loader != None):\n",
    "                test_acc = self.evaluate_model(test_loader)\n",
    "                test_accuracy.append(test_acc)\n",
    "            \n",
    "            if (val_loader != None and test_loader != None and epoch%20 ==0  and verbose == True):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f Test Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                                                  train_accuracy[epoch], val_accuracy[epoch], test_accuracy[epoch]))\n",
    "            elif (val_loader != None and test_loader == None and verbose == True and epoch%20==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                              train_accuracy[epoch], val_accuracy[epoch]))\n",
    "            elif (verbose == True):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f' %(epoch+1, epoch_loss[epoch], train_accuracy[epoch]))\n",
    "        return (bestNetwork, epoch_loss, train_accuracy, val_accuracy, test_accuracy,l2_norms)       \n",
    "\n",
    "\n",
    "\n",
    "def make_data_loaders(train_data,batch_size,val_data=None,test_data=None):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,batch_size,shuffle=True,num_workers=2)\n",
    "    \n",
    "    if (val_data != None): \n",
    "        val_loader = torch.utils.data.DataLoader(val_data,batch_size,shuffle=True,num_workers=2)\n",
    "    else:\n",
    "        val_loader = None\n",
    "    if (test_data != None):\n",
    "        test_loader = torch.utils.data.DataLoader(test_data,batch_size,shuffle=True,num_workers=2)\n",
    "    else:\n",
    "        test_loader = None\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def make_dataset(data,labels):\n",
    "    data = torch.Tensor(data)\n",
    "    labels = torch.IntTensor(labels)\n",
    "    dataset = torch.utils.data.TensorDataset(data,labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loc = '../data/mnist/mnist.pkl'\n",
    "data = np.load(data_loc)\n",
    "mnist_train_data = data[0][0]\n",
    "mnist_train_labels = data[0][1]\n",
    "\n",
    "mnist_train_tensor = torch.utils.data.TensorDataset(torch.Tensor(mnist_train_data),torch.IntTensor(mnist_train_labels))\n",
    "\n",
    "mnist_val_data = data[1][0]\n",
    "mnist_val_labels = data[1][1]\n",
    "\n",
    "mnist_val_tensor = torch.utils.data.TensorDataset(torch.Tensor(mnist_val_data),torch.IntTensor(mnist_val_labels))\n",
    "\n",
    "\n",
    "mnist_test_data = data[2][0]\n",
    "mnist_test_labels = data[2][1]\n",
    "\n",
    "train_dataset = make_dataset(mnist_train_data, mnist_train_labels)\n",
    "val_dataset = make_dataset(mnist_val_data,mnist_val_labels)\n",
    "test_dataset = make_dataset(mnist_test_data,mnist_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print len(mnist_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1.a  Regularization : weight decay, early stopping, dropout, domain prior knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Epoch : 1 Loss : 0.611  Train Accuracy: 0.852\n",
      "Epoch : 2 Loss : 0.291  Train Accuracy: 0.918\n",
      "Epoch : 3 Loss : 0.237  Train Accuracy: 0.933\n",
      "Epoch : 4 Loss : 0.203  Train Accuracy: 0.943\n",
      "Epoch : 5 Loss : 0.176  Train Accuracy: 0.949\n",
      "Epoch : 6 Loss : 0.155  Train Accuracy: 0.956\n",
      "Epoch : 7 Loss : 0.139  Train Accuracy: 0.961\n",
      "Epoch : 8 Loss : 0.125  Train Accuracy: 0.965\n",
      "Epoch : 9 Loss : 0.113  Train Accuracy: 0.969\n",
      "Epoch : 10 Loss : 0.103  Train Accuracy: 0.971\n",
      "Epoch : 11 Loss : 0.095  Train Accuracy: 0.974\n",
      "Epoch : 12 Loss : 0.086  Train Accuracy: 0.976\n",
      "Epoch : 13 Loss : 0.079  Train Accuracy: 0.979\n",
      "Epoch : 14 Loss : 0.073  Train Accuracy: 0.980\n",
      "Epoch : 15 Loss : 0.068  Train Accuracy: 0.982\n",
      "Epoch : 16 Loss : 0.063  Train Accuracy: 0.984\n",
      "Epoch : 17 Loss : 0.058  Train Accuracy: 0.985\n",
      "Epoch : 18 Loss : 0.054  Train Accuracy: 0.986\n",
      "Epoch : 19 Loss : 0.051  Train Accuracy: 0.987\n",
      "Epoch : 20 Loss : 0.047  Train Accuracy: 0.988\n",
      "Epoch : 21 Loss : 0.044  Train Accuracy: 0.989\n",
      "Epoch : 22 Loss : 0.041  Train Accuracy: 0.990\n",
      "Epoch : 23 Loss : 0.039  Train Accuracy: 0.991\n",
      "Epoch : 24 Loss : 0.036  Train Accuracy: 0.991\n",
      "Epoch : 25 Loss : 0.034  Train Accuracy: 0.992\n",
      "Epoch : 26 Loss : 0.032  Train Accuracy: 0.993\n",
      "Epoch : 27 Loss : 0.030  Train Accuracy: 0.994\n",
      "Epoch : 28 Loss : 0.028  Train Accuracy: 0.994\n",
      "Epoch : 29 Loss : 0.026  Train Accuracy: 0.994\n",
      "Epoch : 30 Loss : 0.025  Train Accuracy: 0.995\n",
      "Epoch : 31 Loss : 0.023  Train Accuracy: 0.996\n",
      "Epoch : 32 Loss : 0.022  Train Accuracy: 0.996\n",
      "Epoch : 33 Loss : 0.021  Train Accuracy: 0.996\n",
      "Epoch : 34 Loss : 0.020  Train Accuracy: 0.997\n",
      "Epoch : 35 Loss : 0.018  Train Accuracy: 0.997\n",
      "Epoch : 36 Loss : 0.017  Train Accuracy: 0.997\n",
      "Epoch : 37 Loss : 0.016  Train Accuracy: 0.998\n",
      "Epoch : 38 Loss : 0.015  Train Accuracy: 0.998\n",
      "Epoch : 39 Loss : 0.014  Train Accuracy: 0.998\n",
      "Epoch : 40 Loss : 0.014  Train Accuracy: 0.998\n",
      "Epoch : 41 Loss : 0.013  Train Accuracy: 0.999\n",
      "Epoch : 42 Loss : 0.012  Train Accuracy: 0.999\n",
      "Epoch : 43 Loss : 0.012  Train Accuracy: 0.999\n",
      "Epoch : 44 Loss : 0.011  Train Accuracy: 0.999\n",
      "Epoch : 45 Loss : 0.011  Train Accuracy: 0.999\n",
      "Epoch : 46 Loss : 0.010  Train Accuracy: 0.999\n",
      "Epoch : 47 Loss : 0.010  Train Accuracy: 0.999\n",
      "Epoch : 48 Loss : 0.009  Train Accuracy: 0.999\n",
      "Epoch : 49 Loss : 0.009  Train Accuracy: 0.999\n",
      "Epoch : 50 Loss : 0.008  Train Accuracy: 0.999\n",
      "Epoch : 51 Loss : 0.008  Train Accuracy: 0.999\n",
      "Epoch : 52 Loss : 0.008  Train Accuracy: 1.000\n",
      "Epoch : 53 Loss : 0.007  Train Accuracy: 1.000\n",
      "Epoch : 54 Loss : 0.007  Train Accuracy: 1.000\n",
      "Epoch : 55 Loss : 0.007  Train Accuracy: 1.000\n",
      "Epoch : 56 Loss : 0.006  Train Accuracy: 1.000\n",
      "Epoch : 57 Loss : 0.006  Train Accuracy: 1.000\n",
      "Epoch : 58 Loss : 0.006  Train Accuracy: 1.000\n",
      "Epoch : 59 Loss : 0.006  Train Accuracy: 1.000\n",
      "Epoch : 60 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 61 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 62 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 63 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 64 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 65 Loss : 0.005  Train Accuracy: 1.000\n",
      "Epoch : 66 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 67 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 68 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 69 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 70 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 71 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 72 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 73 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 74 Loss : 0.004  Train Accuracy: 1.000\n",
      "Epoch : 75 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 76 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 77 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 78 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 79 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 80 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 81 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 82 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 83 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 84 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 85 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 86 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 87 Loss : 0.003  Train Accuracy: 1.000\n",
      "Epoch : 88 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 89 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 90 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 91 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 92 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 93 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 94 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 95 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 96 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 97 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 98 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 99 Loss : 0.002  Train Accuracy: 1.000\n",
      "Epoch : 100 Loss : 0.002  Train Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.02\n",
    "batch_size=64\n",
    "num_epochs=100\n",
    "l2_reg = 0\n",
    "batch_weight_decay = l2_reg/(float(len(mnist_train_labels))/float(batch_size))\n",
    "print batch_weight_decay\n",
    "\n",
    "No_reg_model = MLP_MNIST(loss_crit=nn.CrossEntropyLoss())\n",
    "optimizer = torch.optim.SGD(No_reg_model.parameters(),lr=lr )\n",
    "bestNetwork, epoch_loss, train_accuracy, val_accuracy, test_accuracy,l2_norms = No_reg_model.train_model(train_dataset,optimizer,batch_size, num_epochs,early_stopping=False, val_data = None, test_data = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkUgIhLnVAQiInHu/wPjtRRhVuk/tgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e84cb7d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e85c5c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l2_norms)\n",
    "plt.title('L2 Norms')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy)\n",
    "plt.title('Train Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0032\n",
      "Epoch : 1 Loss : 0.610  Train Accuracy: 0.855\n",
      "Epoch : 2 Loss : 0.302  Train Accuracy: 0.915\n",
      "Epoch : 3 Loss : 0.257  Train Accuracy: 0.929\n",
      "Epoch : 4 Loss : 0.227  Train Accuracy: 0.937\n",
      "Epoch : 5 Loss : 0.207  Train Accuracy: 0.944\n",
      "Epoch : 6 Loss : 0.190  Train Accuracy: 0.948\n",
      "Epoch : 7 Loss : 0.177  Train Accuracy: 0.951\n",
      "Epoch : 8 Loss : 0.167  Train Accuracy: 0.955\n",
      "Epoch : 9 Loss : 0.158  Train Accuracy: 0.957\n",
      "Epoch : 10 Loss : 0.150  Train Accuracy: 0.959\n",
      "Epoch : 11 Loss : 0.144  Train Accuracy: 0.962\n",
      "Epoch : 12 Loss : 0.139  Train Accuracy: 0.963\n",
      "Epoch : 13 Loss : 0.134  Train Accuracy: 0.965\n",
      "Epoch : 14 Loss : 0.130  Train Accuracy: 0.967\n",
      "Epoch : 15 Loss : 0.126  Train Accuracy: 0.968\n",
      "Epoch : 16 Loss : 0.123  Train Accuracy: 0.969\n",
      "Epoch : 17 Loss : 0.120  Train Accuracy: 0.970\n",
      "Epoch : 18 Loss : 0.117  Train Accuracy: 0.970\n",
      "Epoch : 19 Loss : 0.115  Train Accuracy: 0.971\n",
      "Epoch : 20 Loss : 0.113  Train Accuracy: 0.972\n",
      "Epoch : 21 Loss : 0.110  Train Accuracy: 0.973\n",
      "Epoch : 22 Loss : 0.108  Train Accuracy: 0.973\n",
      "Epoch : 23 Loss : 0.107  Train Accuracy: 0.974\n",
      "Epoch : 24 Loss : 0.105  Train Accuracy: 0.974\n",
      "Epoch : 25 Loss : 0.103  Train Accuracy: 0.975\n",
      "Epoch : 26 Loss : 0.102  Train Accuracy: 0.976\n",
      "Epoch : 27 Loss : 0.101  Train Accuracy: 0.976\n",
      "Epoch : 28 Loss : 0.100  Train Accuracy: 0.977\n",
      "Epoch : 29 Loss : 0.099  Train Accuracy: 0.977\n",
      "Epoch : 30 Loss : 0.098  Train Accuracy: 0.977\n",
      "Epoch : 31 Loss : 0.097  Train Accuracy: 0.978\n",
      "Epoch : 32 Loss : 0.096  Train Accuracy: 0.977\n",
      "Epoch : 33 Loss : 0.095  Train Accuracy: 0.978\n",
      "Epoch : 34 Loss : 0.094  Train Accuracy: 0.978\n",
      "Epoch : 35 Loss : 0.094  Train Accuracy: 0.979\n",
      "Epoch : 36 Loss : 0.093  Train Accuracy: 0.979\n",
      "Epoch : 37 Loss : 0.092  Train Accuracy: 0.979\n",
      "Epoch : 38 Loss : 0.092  Train Accuracy: 0.979\n",
      "Epoch : 39 Loss : 0.091  Train Accuracy: 0.979\n",
      "Epoch : 40 Loss : 0.091  Train Accuracy: 0.980\n",
      "Epoch : 41 Loss : 0.090  Train Accuracy: 0.980\n",
      "Epoch : 42 Loss : 0.090  Train Accuracy: 0.980\n",
      "Epoch : 43 Loss : 0.089  Train Accuracy: 0.979\n",
      "Epoch : 44 Loss : 0.089  Train Accuracy: 0.980\n",
      "Epoch : 45 Loss : 0.089  Train Accuracy: 0.980\n",
      "Epoch : 46 Loss : 0.088  Train Accuracy: 0.980\n",
      "Epoch : 47 Loss : 0.088  Train Accuracy: 0.980\n",
      "Epoch : 48 Loss : 0.088  Train Accuracy: 0.980\n",
      "Epoch : 49 Loss : 0.087  Train Accuracy: 0.981\n",
      "Epoch : 50 Loss : 0.087  Train Accuracy: 0.981\n",
      "Epoch : 51 Loss : 0.087  Train Accuracy: 0.981\n",
      "Epoch : 52 Loss : 0.086  Train Accuracy: 0.981\n",
      "Epoch : 53 Loss : 0.086  Train Accuracy: 0.981\n",
      "Epoch : 54 Loss : 0.086  Train Accuracy: 0.981\n",
      "Epoch : 55 Loss : 0.086  Train Accuracy: 0.981\n",
      "Epoch : 56 Loss : 0.085  Train Accuracy: 0.981\n",
      "Epoch : 57 Loss : 0.085  Train Accuracy: 0.981\n",
      "Epoch : 58 Loss : 0.085  Train Accuracy: 0.981\n",
      "Epoch : 59 Loss : 0.085  Train Accuracy: 0.981\n",
      "Epoch : 60 Loss : 0.085  Train Accuracy: 0.981\n",
      "Epoch : 61 Loss : 0.084  Train Accuracy: 0.981\n",
      "Epoch : 62 Loss : 0.084  Train Accuracy: 0.982\n",
      "Epoch : 63 Loss : 0.084  Train Accuracy: 0.981\n",
      "Epoch : 64 Loss : 0.084  Train Accuracy: 0.982\n",
      "Epoch : 65 Loss : 0.084  Train Accuracy: 0.982\n",
      "Epoch : 66 Loss : 0.084  Train Accuracy: 0.981\n",
      "Epoch : 67 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 68 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 69 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 70 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 71 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 72 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 73 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 74 Loss : 0.083  Train Accuracy: 0.982\n",
      "Epoch : 75 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 76 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 77 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 78 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 79 Loss : 0.082  Train Accuracy: 0.983\n",
      "Epoch : 80 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 81 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 82 Loss : 0.082  Train Accuracy: 0.983\n",
      "Epoch : 83 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 84 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 85 Loss : 0.081  Train Accuracy: 0.983\n",
      "Epoch : 86 Loss : 0.082  Train Accuracy: 0.982\n",
      "Epoch : 87 Loss : 0.081  Train Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "lr = 0.02\n",
    "batch_size=64\n",
    "num_epochs=100\n",
    "l2_reg = 2.5\n",
    "batch_weight_decay = l2_reg/(float(len(mnist_train_labels))/float(batch_size))\n",
    "print batch_weight_decay\n",
    "\n",
    "reg_model = MLP_MNIST(loss_crit=nn.CrossEntropyLoss())\n",
    "optimizer = torch.optim.SGD(reg_model.parameters(),lr=lr,weight_decay = batch_weight_decay )\n",
    "bestNetwork, epoch_loss, train_accuracy, val_accuracy, test_accuracy,l2_norms = reg_model.train_model(train_dataset,optimizer,batch_size, num_epochs,early_stopping=False, val_data = None, test_data = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l2_norms)\n",
    "plt.title('L2 Norms')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_accuracy)\n",
    "plt.title('Train Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dropout_MLP(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(Dropout_MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,800)\n",
    "        self.fc2 = nn.Linear(800,800)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc3 = nn.Linear(800,10)\n",
    "        \n",
    "        self.insize = 28*28\n",
    "        \n",
    "        self.loss_crit = nn.NLLLoss()\n",
    "        \n",
    "        params = list(self.parameters())\n",
    "        for param in params:\n",
    "            if len(param.shape)>1:\n",
    "                nn.init.xavier_normal(param)\n",
    "            else:\n",
    "                nn.init.constant(param,0)\n",
    "                \n",
    "                \n",
    "    def forward(self,x):\n",
    "        lsm = nn.LogSoftmax(1)\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = nn.functional.relu(a1)\n",
    "        \n",
    "        a2 = self.fc2(h1)\n",
    "        d2 = self.dropout(a2)\n",
    "        h2 = nn.functional.relu(d2)\n",
    "        \n",
    "        logits = self.fc3(h2)\n",
    "        probs = lsm(logits)\n",
    "        \n",
    "        return probs\n",
    "    def predictions(self,x,eval_type, N=1):\n",
    "        self.train()\n",
    "        lsm = nn.Softmax(1)\n",
    "        if eval_type == 'average_pre':\n",
    "            averages = torch.zeros(x.shape[0],10)\n",
    "        elif eval_type=='average_preds':\n",
    "            averages = torch.zeros(x.shape[0])\n",
    "        for i in range(N):\n",
    "\n",
    "            a1 = self.fc1(x)\n",
    "            h1 = nn.functional.relu(a1)\n",
    "        \n",
    "            a2 = self.fc2(h1)\n",
    "            if eval_type == 'half':\n",
    "                self.eval()\n",
    "                d2 = a2\n",
    "            else:\n",
    "                d2 = self.dropout(a2)\n",
    "            h2 = nn.functional.relu(d2)\n",
    "            if (eval_type == 'half'):\n",
    "                h2 = h2*0.5\n",
    "                logits = self.fc3(h2)\n",
    "                probs = lsm(logits)\n",
    "                _,preds = torch.max(probs.data,1)\n",
    "                return preds\n",
    "            elif (eval_type == 'average_pre'):\n",
    "                logits = self.fc3(h2)\n",
    "                averages += logits.data\n",
    "            elif (eval_type == 'average_preds'):\n",
    "                logits = self.fc3(h2)\n",
    "                probs = lsm(logits)\n",
    "                _,preds = torch.max(probs.data,1)\n",
    "                preds = preds.type(torch.FloatTensor)\n",
    "                averages += preds\n",
    "            \n",
    "        if (eval_type == 'average_pre'):\n",
    "            averages = torch.div(averages,N)\n",
    "            averages = Variable(averages)\n",
    "            probs = lsm(averages)\n",
    "            _, preds = torch.max(probs.data,1)\n",
    "            return preds\n",
    "\n",
    "        if (eval_type == 'average_preds'):\n",
    "            preds = torch.div(averages,N)\n",
    "            preds = torch.round(preds)\n",
    "            preds = preds.type(torch.LongTensor)\n",
    "            return preds\n",
    "\n",
    "    \n",
    "    def evaluate_model(self,loader,eval_type,N=1):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_index,(inputs,targets) in enumerate(loader):\n",
    "            x, targets = Variable(inputs.view([-1,self.insize])), Variable(targets)\n",
    "\n",
    "            preds = self.predictions(x,eval_type,N)\n",
    "            correct += preds.eq(targets.data).sum()\n",
    "            total += targets.size(0)\n",
    "        accuracy = (correct/float(total))\n",
    "        return accuracy\n",
    "    \n",
    "    def prediction(self,logits):\n",
    "        \n",
    "        values, indices = torch.max(logits.data,1)\n",
    "        \n",
    "        return values, indices\n",
    "    \n",
    "    \n",
    "    def train_model(self, train_data,optimizer,batch_size, num_epochs,early_stopping=False, val_data = None, test_data = None, verbose=True ):\n",
    "        #prepare optimizer\n",
    "        train_loader, val_loader, test_loader = make_data_loaders(train_data,batch_size,val_data,test_data)\n",
    "        \n",
    "        bestValAcc = 0\n",
    "        bestNetwork = 0\n",
    "        train_accuracy = []\n",
    "        val_accuracy = []\n",
    "        test_accuracy = []\n",
    "        epoch_loss=[]\n",
    "        for epoch in range(num_epochs):\n",
    "            losses = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "\n",
    "            for batch_index, (inputs,targets) in enumerate(train_loader):\n",
    "                inputs = Variable(inputs.view([-1,self.insize]))\n",
    "                targets = Variable(targets)\n",
    "                optimizer.zero_grad()\n",
    "                logits = self.forward(inputs)\n",
    "                _,preds = self.prediction(logits)\n",
    "                correct += preds.eq(targets.data).sum()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "                loss = self.loss_crit(logits,targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.data[0])\n",
    "            epoch_loss.append(np.mean(losses))\n",
    "            train_accuracy.append(correct/float(total))\n",
    "            \n",
    "            if (val_loader != None):\n",
    "                val_acc = evaluate_model(val_loader)\n",
    "                val_accuracy.append(val_acc)\n",
    "                            \n",
    "                if val_acc > bestValAcc:\n",
    "                    bestNetwork = self\n",
    "                    bestValAcc= val_acc\n",
    "                \n",
    "                if (early_stopping and val_acc < bestValAcc) :\n",
    "                    return bestNetwork\n",
    "        \n",
    "                \n",
    "            \n",
    "            if (test_loader != None):\n",
    "                test_acc = evaluate_model(test_loader)\n",
    "                test_accuracy.append(test_acc)\n",
    "            \n",
    "            if (val_loader != None and test_loader != None and verbose == True and epoch%10==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f Test Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                                                  train_accuracy[epoch], val_accuracy[epoch], test_accuracy[epoch]))\n",
    "            elif (val_loader != None and test_loader == None and verbose == True and epoch%20==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                              train_accuracy[epoch], val_accuracy[epoch]))\n",
    "            elif (verbose == True and epoch%10==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f' %(epoch+1, epoch_loss[epoch], train_accuracy[epoch]))\n",
    "        return (bestNetwork, epoch_loss, train_accuracy, val_accuracy, test_accuracy)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 0.664  Train Accuracy: 0.816\n",
      "Epoch : 11 Loss : 0.114  Train Accuracy: 0.967\n",
      "Epoch : 21 Loss : 0.065  Train Accuracy: 0.981\n",
      "Epoch : 31 Loss : 0.040  Train Accuracy: 0.989\n",
      "Epoch : 41 Loss : 0.027  Train Accuracy: 0.993\n",
      "Epoch : 51 Loss : 0.019  Train Accuracy: 0.995\n",
      "Epoch : 61 Loss : 0.014  Train Accuracy: 0.997\n",
      "Epoch : 71 Loss : 0.010  Train Accuracy: 0.998\n",
      "Epoch : 81 Loss : 0.007  Train Accuracy: 0.999\n",
      "Epoch : 91 Loss : 0.006  Train Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "lr = 0.02\n",
    "batch_size=64\n",
    "num_epochs=100\n",
    "DropoutModel = Dropout_MLP(0.5)\n",
    "optimizer = torch.optim.SGD(DropoutModel.parameters(),lr=lr )\n",
    "results = DropoutModel.train_model(train_dataset,optimizer,batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10*i for i in range(1,10)]\n",
    "test_loader,_,_ = make_data_loaders(test_dataset,64,val_dataset,test_dataset)\n",
    "half_acc = [0]*len(Ns)\n",
    "pre_acc = [0]*len(Ns)\n",
    "pred_acc = [0]*len(Ns)\n",
    "for i,N in enumerate(Ns):\n",
    "    half_acc[i] = DropoutModel.evaluate_model(test_loader,'half',N)\n",
    "    pre_acc[i] = DropoutModel.evaluate_model(test_loader,'average_pre',N)\n",
    "    pred_acc[i] = DropoutModel.evaluate_model(test_loader,'average_preds',N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b.i-iii Accuracy Plots for different Dropout evaluation procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgqAyEiIoAMhIiIqP4CeSviHnCrwUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e91824510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Ns,half_acc, label='Half Hidden layer output')\n",
    "plt.plot(Ns,pre_acc, label='Average Pre-hidden layer values')\n",
    "plt.plot(Ns,pred_acc,label='Average predictions')\n",
    "plt.legend()\n",
    "plt.title('Different evaluation procedures using dropout')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different types of ensemble procedures shown here are:\n",
    "\n",
    "i) When halving the output of the dropout mask, one can conclude that this is a bagging method. As shown during theory, this is a geometric mean of N different networks.\n",
    "\n",
    "ii) This method can be closely related to the arithmetic mean of the logit outputs. Similar to boosting.\n",
    "\n",
    "iii) This is also an arithmetic mean of the post softmax values, again similar to boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,batch_norm=False):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=(3,3), padding=1)\n",
    "        if (batch_norm):\n",
    "            self.bnorm1 = nn.BatchNorm2d(16)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(3,3), padding=1)\n",
    "        if (batch_norm):\n",
    "            self.bnorm2 = nn.BatchNorm2d(32)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(3,3), padding=1)\n",
    "        if (batch_norm):\n",
    "            self.bnorm3 = nn.BatchNorm2d(64)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3), padding=1)\n",
    "        if (batch_norm):\n",
    "            self.bnorm4 = nn.BatchNorm2d(128)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "        self.fc = nn.Linear(128,10)\n",
    "        self.batch_norm=batch_norm\n",
    "        #self.indims = [-1,1,28,28]\n",
    "        \n",
    "        self.loss_crit = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        a1 = self.conv1(x)\n",
    "        d1 = self.dropout1(a1)\n",
    "        if (self.batch_norm):\n",
    "            d1 = self.bnorm1(d1)\n",
    "        d1 = nn.functional.relu(d1)\n",
    "        p1 = self.pool1(d1)\n",
    "        \n",
    "        a2 = self.conv2(p1)\n",
    "        d2 = self.dropout2(a2)\n",
    "        if (self.batch_norm):\n",
    "            d2 = self.bnorm1(d2)\n",
    "        d2 = nn.functional.relu(d2)\n",
    "        p2 = self.pool2(d2)\n",
    "        \n",
    "        a3 = self.conv3(p2)\n",
    "        d3 = self.dropout3(a3)\n",
    "        if (self.batch_norm):\n",
    "            d3 = self.bnorm1(d3)\n",
    "        d3 = nn.functional.relu(d3)\n",
    "        p3 = self.pool3(d3)\n",
    "        \n",
    "        a4 = self.conv4(p3)\n",
    "        d4=self.dropout4(a4)\n",
    "        if (self.batch_norm):\n",
    "            d4 = self.bnorm1(d4)\n",
    "        d4 = nn.functional.relu(d4)\n",
    "        p4 = self.pool4(d4)\n",
    "        \n",
    "        logits = self.fc(p4.squeeze())\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def prediction(self,logits):\n",
    "        \n",
    "        _, preds = torch.max(logits.data,1)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def evaluate_model(self,loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_index,(inputs,targets) in enumerate(loader):\n",
    "            x, targets = Variable(inputs.view([-1,1,28,28])), Variable(targets)\n",
    "\n",
    "            logits = self.forward(x)\n",
    "            preds = self.prediction(logits)\n",
    "            correct += preds.eq(targets.data).sum()\n",
    "            total += targets.size(0)\n",
    "        accuracy = (correct/float(total))\n",
    "        return accuracy\n",
    "    \n",
    "    def train_model(self, train_data, optimizer,batch_size, num_epochs,early_stopping=False, val_data = None, test_data = None, verbose=True ):\n",
    "        #prepare optimizer\n",
    "        train_loader, val_loader, test_loader = make_data_loaders(train_data,batch_size,val_data,test_data)\n",
    "        \n",
    "        bestValAcc = 0\n",
    "        bestNetwork = 0\n",
    "        train_accuracy = []\n",
    "        val_accuracy = []\n",
    "        test_accuracy = []\n",
    "        epoch_loss=[]\n",
    "        for epoch in range(num_epochs):\n",
    "            losses = []\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "\n",
    "            for batch_index, (inputs,targets) in enumerate(train_loader):\n",
    "                inputs = Variable(inputs.view([-1,1,28,28]))\n",
    "                targets = Variable(targets)\n",
    "                optimizer.zero_grad()\n",
    "                logits = self.forward(inputs)\n",
    "                preds = self.prediction(logits)\n",
    "                correct += preds.eq(targets.data).sum()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "                loss = self.loss_crit(logits,targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.data[0])\n",
    "            epoch_loss.append(np.mean(losses))\n",
    "            train_accuracy.append(correct/float(total))\n",
    "            \n",
    "            if (val_loader != None):\n",
    "                val_acc = self.evaluate_model(val_loader)\n",
    "                val_accuracy.append(val_acc)\n",
    "                            \n",
    "                if val_acc > bestValAcc:\n",
    "                    bestNetwork = self\n",
    "                    bestValAcc= val_acc\n",
    "                \n",
    "                if (early_stopping and val_acc < bestValAcc) :\n",
    "                    return bestNetwork\n",
    "        \n",
    "                \n",
    "            \n",
    "            if (test_loader != None):\n",
    "                test_acc = self.evaluate_model(test_loader)\n",
    "                test_accuracy.append(test_acc)\n",
    "            \n",
    "            if (val_loader != None and test_loader != None and verbose == True):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f Test Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                                                  train_accuracy[epoch], val_accuracy[epoch], test_accuracy[epoch]))\n",
    "            elif (val_loader != None and test_loader == None and verbose == True and epoch%20==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f Validation Accuracy: %.3f' % (epoch+1,epoch_loss[epoch],\\\n",
    "                                                                                              train_accuracy[epoch], val_accuracy[epoch]))\n",
    "            elif (verbose == True and epoch%20==0):\n",
    "                print('Epoch : %d Loss : %.3f  Train Accuracy: %.3f' %(epoch+1, epoch_loss[epoch], train_accuracy[epoch]))\n",
    "        return (bestNetwork, epoch_loss, train_accuracy, val_accuracy, test_accuracy,l2_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print mnist_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_train_data_r = mnist_train_data.reshape((mnist_train_data.shape[0],28,28))\n",
    "mnist_val_data_r = mnist_val_data.reshape((mnist_val_data.shape[0],28,28))\n",
    "mnist_test_data_r = mnist_test_data.reshape((mnist_test_data.shape[0],28,28))\n",
    "\n",
    "mnist_ctrain_dataset = make_dataset(mnist_train_data_r,mnist_train_labels)\n",
    "mnist_cval_dataset = make_dataset(mnist_val_data_r, mnist_val_labels)\n",
    "mnist_ctest_dataset = make_dataset(mnist_test_data_r, mnist_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 2.294  Train Accuracy: 0.133 Validation Accuracy: 0.155 Test Accuracy: 0.145\n",
      "Epoch : 2 Loss : 2.032  Train Accuracy: 0.289 Validation Accuracy: 0.480 Test Accuracy: 0.461\n",
      "Epoch : 3 Loss : 1.118  Train Accuracy: 0.624 Validation Accuracy: 0.727 Test Accuracy: 0.733\n",
      "Epoch : 4 Loss : 0.704  Train Accuracy: 0.773 Validation Accuracy: 0.827 Test Accuracy: 0.818\n",
      "Epoch : 5 Loss : 0.521  Train Accuracy: 0.836 Validation Accuracy: 0.863 Test Accuracy: 0.860\n",
      "Epoch : 6 Loss : 0.457  Train Accuracy: 0.857 Validation Accuracy: 0.880 Test Accuracy: 0.885\n",
      "Epoch : 7 Loss : 0.435  Train Accuracy: 0.870 Validation Accuracy: 0.882 Test Accuracy: 0.889\n",
      "Epoch : 8 Loss : 0.401  Train Accuracy: 0.881 Validation Accuracy: 0.885 Test Accuracy: 0.885\n",
      "Epoch : 9 Loss : 0.418  Train Accuracy: 0.881 Validation Accuracy: 0.880 Test Accuracy: 0.883\n",
      "Epoch : 10 Loss : 0.405  Train Accuracy: 0.881 Validation Accuracy: 0.893 Test Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "loss_crit = nn.CrossEntropyLoss()\n",
    "MNIST_ConvNet = ConvNet()\n",
    "optimizer = torch.optim.SGD(MNIST_ConvNet.parameters(),lr=lr)\n",
    "train_results = MNIST_ConvNet.train_model(mnist_ctrain_dataset,optimizer, batch_size,num_epochs, val_data = mnist_cval_dataset, test_data = mnist_ctest_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 0.408  Train Accuracy: 0.884 Validation Accuracy: 0.892 Test Accuracy: 0.894\n",
      "Epoch : 2 Loss : 0.402  Train Accuracy: 0.886 Validation Accuracy: 0.895 Test Accuracy: 0.891\n",
      "Epoch : 3 Loss : 0.413  Train Accuracy: 0.885 Validation Accuracy: 0.899 Test Accuracy: 0.893\n",
      "Epoch : 4 Loss : 0.404  Train Accuracy: 0.886 Validation Accuracy: 0.897 Test Accuracy: 0.894\n",
      "Epoch : 5 Loss : 0.405  Train Accuracy: 0.886 Validation Accuracy: 0.896 Test Accuracy: 0.894\n",
      "Epoch : 6 Loss : 0.400  Train Accuracy: 0.886 Validation Accuracy: 0.894 Test Accuracy: 0.896\n",
      "Epoch : 7 Loss : 0.398  Train Accuracy: 0.887 Validation Accuracy: 0.894 Test Accuracy: 0.899\n",
      "Epoch : 8 Loss : 0.415  Train Accuracy: 0.886 Validation Accuracy: 0.902 Test Accuracy: 0.897\n",
      "Epoch : 9 Loss : 0.397  Train Accuracy: 0.886 Validation Accuracy: 0.895 Test Accuracy: 0.894\n",
      "Epoch : 10 Loss : 0.402  Train Accuracy: 0.887 Validation Accuracy: 0.899 Test Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "loss_crit = nn.CrossEntropyLoss()\n",
    "BN_MNIST_ConvNet = ConvNet(batch_norm=True)\n",
    "optimizer = torch.optim.SGD(BN_MNIST_ConvNet.parameters(),lr=lr)\n",
    "train_results = MNIST_ConvNet.train_model(mnist_ctrain_dataset,optimizer, batch_size,num_epochs, val_data = mnist_cval_dataset, test_data = mnist_ctest_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
